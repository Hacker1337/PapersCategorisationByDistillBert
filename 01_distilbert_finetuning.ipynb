{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "335b3dd5",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49915cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "model_path = \"distilbert/distilbert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17b8c5",
   "metadata": {},
   "source": [
    "# Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3596fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from article_classifier.dataset import load_arxiv_dataset\n",
    "\n",
    "dataset = load_arxiv_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d218d7",
   "metadata": {},
   "source": [
    "### Data preliminary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ffa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "category_counts = Counter()\n",
    "\n",
    "for term in dataset[\"terms\"]:\n",
    "    for category in term:\n",
    "        category_counts[category] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249dd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cs.CV', 30413),\n",
       " ('cs.LG', 29067),\n",
       " ('stat.ML', 15578),\n",
       " ('cs.AI', 7944),\n",
       " ('eess.IV', 2484),\n",
       " ('cs.RO', 1896),\n",
       " ('cs.CL', 1620),\n",
       " ('cs.NE', 1296),\n",
       " ('cs.CR', 717),\n",
       " ('cs.SI', 678),\n",
       " ('math.OC', 666),\n",
       " ('eess.SP', 621),\n",
       " ('cs.GR', 583),\n",
       " ('cs.MM', 523),\n",
       " ('cs.SY', 444),\n",
       " ('cs.IR', 442),\n",
       " ('cs.MA', 375),\n",
       " ('cs.HC', 359),\n",
       " ('eess.SY', 345),\n",
       " ('stat.AP', 294)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f84d38",
   "metadata": {},
   "source": [
    "1. make trainable categories.\n",
    "2. train test split.\n",
    "3. preprocess to tokens ids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbc1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from article_classifier.dataset import id2label, label2id, create_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc4a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_add_simple_categories(example):\n",
    "    labels = [0.] * len(id2label)\n",
    "    labels[label2id[\"CV\"]] = float(\"cs.CV\" in example[\"terms\"])\n",
    "    labels[label2id[\"AI\"]] = float(\"cs.AI\" in example[\"terms\"])\n",
    "    labels[label2id[\"ML\"]] = float((\"stat.ML\" in example[\"terms\"]) or (\"cs.LG\" in example[\"terms\"]))\n",
    "    labels[label2id[\"NE\"]] = float(\"cs.NE\" in example[\"terms\"])\n",
    "    labels[label2id[\"CL\"]] = float(\"cs.CL\" in example[\"terms\"])\n",
    "    example[\"labels\"] = labels\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(preprocess_add_simple_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb245ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>terms</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
       "      <td>Stereo matching is one of the widely used tech...</td>\n",
       "      <td>[cs.CV, cs.LG]</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "      <td>[cs.CV, cs.AI, cs.LG]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
       "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
       "      <td>[cs.CV, cs.AI]</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
       "      <td>Consistency training has proven to be an advan...</td>\n",
       "      <td>[cs.CV]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background-Foreground Segmentation for Interio...</td>\n",
       "      <td>To ensure safety in automated driving, the cor...</td>\n",
       "      <td>[cs.CV, cs.LG]</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles  \\\n",
       "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
       "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
       "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
       "4  Background-Foreground Segmentation for Interio...   \n",
       "\n",
       "                                           summaries                  terms  \\\n",
       "0  Stereo matching is one of the widely used tech...         [cs.CV, cs.LG]   \n",
       "1  The recent advancements in artificial intellig...  [cs.CV, cs.AI, cs.LG]   \n",
       "2  In this paper, we proposed a novel mutual cons...         [cs.CV, cs.AI]   \n",
       "3  Consistency training has proven to be an advan...                [cs.CV]   \n",
       "4  To ensure safety in automated driving, the cor...         [cs.CV, cs.LG]   \n",
       "\n",
       "                      labels  \n",
       "0  [1.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "1  [1.0, 1.0, 1.0, 0.0, 0.0]  \n",
       "2  [1.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "4  [1.0, 0.0, 1.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d772693c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey on Semantic Stereo Matching / Semantic Depth Estimation\n",
      "\n",
      "Stereo matching is one of the widely used techniques for inferring depth from\n",
      "stereo images owing to its robustness and speed. It has become one of the major\n",
      "topics of research since it finds its applications in autonomous driving,\n",
      "robotic navigation, 3D reconstruction, and many other fields. Finding pixel\n",
      "correspondences in non-textured, occluded and reflective areas is the major\n",
      "challenge in stereo matching. Recent developments have shown that semantic cues\n",
      "from image segmentation can be used to improve the results of stereo matching.\n",
      "Many deep neural network architectures have been proposed to leverage the\n",
      "advantages of semantic segmentation in stereo matching. This paper aims to give\n",
      "a comparison among the state of art networks both in terms of accuracy and in\n",
      "terms of speed which are of higher importance in real-time applications.\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0].titles)\n",
    "print()\n",
    "print(df.iloc[0].summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b432134c",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745824c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_counter = 0\n",
    "def preprocess_function(examples):\n",
    "    text = []\n",
    "    for title, abstract in zip(examples[\"titles\"], examples[\"summaries\"]):\n",
    "        if dataset_counter % 5 == 0: # adding some entities without abstracts\n",
    "            text.append(create_prompt(title, \"\"))\n",
    "        else:\n",
    "            text.append(create_prompt(title, abstract))\n",
    "    return tokenizer(text, truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6110596e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928e965bd60b4ff880a0fe0df8b4a626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51774 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_arxiv = dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f6ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['titles', 'summaries', 'terms', 'labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 51774\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004efaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['titles', 'summaries', 'terms', 'labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 41419\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['titles', 'summaries', 'terms', 'labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 10355\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "split_dataset = tokenized_arxiv.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "print(split_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c138f441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(split_dataset[\"train\"][\"labels\"][:5][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb71c4e",
   "metadata": {},
   "source": [
    "## Pipeline preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39fafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "   predictions, labels = eval_pred\n",
    "   predictions = (predictions > 0).astype(int).reshape(-1)\n",
    "   return clf_metrics.compute(predictions=predictions, references=labels.astype(int).reshape(-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e963a5",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8fd2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=len(id2label),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    problem_type=\"multi_label_classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a830f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"~/.cache/huggingface/checkpoints/distilbert-arxiv2\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"all\",\n",
    "    run_name=\"DistillBertFinetuning_With Skipped Abstracts\",\n",
    "    logging_steps=20,\n",
    "    eval_on_start=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"test\"].select(range(20 * 16)),\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c4a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='681' max='5178' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 677/5178 01:04 < 07:12, 10.40 it/s, Epoch 0.26/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.671250</td>\n",
       "      <td>0.778125</td>\n",
       "      <td>0.672811</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.820225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.544600</td>\n",
       "      <td>0.456104</td>\n",
       "      <td>0.778125</td>\n",
       "      <td>0.672811</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.820225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.415200</td>\n",
       "      <td>0.433664</td>\n",
       "      <td>0.771875</td>\n",
       "      <td>0.562874</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.528090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.405500</td>\n",
       "      <td>0.390882</td>\n",
       "      <td>0.816875</td>\n",
       "      <td>0.698249</td>\n",
       "      <td>0.644487</td>\n",
       "      <td>0.761798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.381500</td>\n",
       "      <td>0.355134</td>\n",
       "      <td>0.856875</td>\n",
       "      <td>0.722424</td>\n",
       "      <td>0.784211</td>\n",
       "      <td>0.669663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.333400</td>\n",
       "      <td>0.336038</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.733668</td>\n",
       "      <td>0.831909</td>\n",
       "      <td>0.656180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.317300</td>\n",
       "      <td>0.313339</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.674157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.297600</td>\n",
       "      <td>0.313638</td>\n",
       "      <td>0.874375</td>\n",
       "      <td>0.750929</td>\n",
       "      <td>0.837017</td>\n",
       "      <td>0.680899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.305131</td>\n",
       "      <td>0.881875</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.687640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.314800</td>\n",
       "      <td>0.294592</td>\n",
       "      <td>0.883750</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.858726</td>\n",
       "      <td>0.696629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.303500</td>\n",
       "      <td>0.300725</td>\n",
       "      <td>0.878125</td>\n",
       "      <td>0.756554</td>\n",
       "      <td>0.851124</td>\n",
       "      <td>0.680899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.313300</td>\n",
       "      <td>0.298113</td>\n",
       "      <td>0.881875</td>\n",
       "      <td>0.761665</td>\n",
       "      <td>0.867816</td>\n",
       "      <td>0.678652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.323300</td>\n",
       "      <td>0.291830</td>\n",
       "      <td>0.885625</td>\n",
       "      <td>0.767471</td>\n",
       "      <td>0.883041</td>\n",
       "      <td>0.678652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.301900</td>\n",
       "      <td>0.305942</td>\n",
       "      <td>0.878125</td>\n",
       "      <td>0.752224</td>\n",
       "      <td>0.865497</td>\n",
       "      <td>0.665169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.284800</td>\n",
       "      <td>0.291299</td>\n",
       "      <td>0.883750</td>\n",
       "      <td>0.759067</td>\n",
       "      <td>0.896024</td>\n",
       "      <td>0.658427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.287641</td>\n",
       "      <td>0.888750</td>\n",
       "      <td>0.771208</td>\n",
       "      <td>0.900901</td>\n",
       "      <td>0.674157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.271900</td>\n",
       "      <td>0.285683</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.773869</td>\n",
       "      <td>0.877493</td>\n",
       "      <td>0.692135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.306600</td>\n",
       "      <td>0.280669</td>\n",
       "      <td>0.891250</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>0.881690</td>\n",
       "      <td>0.703371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.280316</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.906344</td>\n",
       "      <td>0.674157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.282699</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.774359</td>\n",
       "      <td>0.901493</td>\n",
       "      <td>0.678652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.276583</td>\n",
       "      <td>0.889375</td>\n",
       "      <td>0.774522</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.683146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>0.275673</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.899135</td>\n",
       "      <td>0.701124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.284800</td>\n",
       "      <td>0.276603</td>\n",
       "      <td>0.893125</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.905325</td>\n",
       "      <td>0.687640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.281974</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.776501</td>\n",
       "      <td>0.899408</td>\n",
       "      <td>0.683146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.311000</td>\n",
       "      <td>0.279177</td>\n",
       "      <td>0.886250</td>\n",
       "      <td>0.769036</td>\n",
       "      <td>0.883382</td>\n",
       "      <td>0.680899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.283800</td>\n",
       "      <td>0.273649</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.780612</td>\n",
       "      <td>0.902655</td>\n",
       "      <td>0.687640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.298800</td>\n",
       "      <td>0.274483</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.685393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.305800</td>\n",
       "      <td>0.288720</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.789082</td>\n",
       "      <td>0.880886</td>\n",
       "      <td>0.714607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.269700</td>\n",
       "      <td>0.273054</td>\n",
       "      <td>0.889375</td>\n",
       "      <td>0.774522</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.683146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.268570</td>\n",
       "      <td>0.898125</td>\n",
       "      <td>0.792357</td>\n",
       "      <td>0.914706</td>\n",
       "      <td>0.698876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.282700</td>\n",
       "      <td>0.283456</td>\n",
       "      <td>0.888750</td>\n",
       "      <td>0.776382</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.694382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.285300</td>\n",
       "      <td>0.264329</td>\n",
       "      <td>0.901250</td>\n",
       "      <td>0.802005</td>\n",
       "      <td>0.906516</td>\n",
       "      <td>0.719101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>0.277199</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.881844</td>\n",
       "      <td>0.687640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.256600</td>\n",
       "      <td>0.274006</td>\n",
       "      <td>0.891250</td>\n",
       "      <td>0.778061</td>\n",
       "      <td>0.899705</td>\n",
       "      <td>0.685393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.269518</td>\n",
       "      <td>0.894375</td>\n",
       "      <td>0.790062</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.714607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\transformers\\trainer.py:2240\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2238\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\transformers\\trainer.py:2555\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2548\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2549\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2551\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2553\u001b[0m )\n\u001b[0;32m   2554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2555\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2558\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2559\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2560\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2561\u001b[0m ):\n\u001b[0;32m   2562\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2563\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\transformers\\trainer.py:3791\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[0;32m   3789\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 3791\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3793\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\accelerate\\accelerator.py:2553\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2551\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2553\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5343146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Unable to save notebook session history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▇▁▁▁▃▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇███▇█▇█▇▇█</td></tr><tr><td>eval/f1</td><td>▇▄▄▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇█▇█▇▇█</td></tr><tr><td>eval/loss</td><td>▂█▄▄▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/model_preparation_time</td><td>▁</td></tr><tr><td>eval/precision</td><td>▆▁▁▂▃▅▆▆▆▇▇▇▇▇▇██▇▇██████▇██▇██▇█▇█▇</td></tr><tr><td>eval/recall</td><td>▆██▁▇▄▄▅▅▅▅▅▅▅▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▅▅▅</td></tr><tr><td>eval/runtime</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▄▁▇▇▇█▆▆▇▆█▇█▇▆▅▅▆▇▇█▇█▇▇▇▆█▇▇▇█▅▆▅▇</td></tr><tr><td>eval/steps_per_second</td><td>█▁▃▃▄▄▃▃▃▃▄▃▄▃▃▂▃▃▃▄▄▄▄▄▃▄▃▄▃▃▃▄▃▃▃▃</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▁▁▂▂▅▃▅▄▅▂▆▃▆▂▂▄▅▃▃▄▆▃▄▂▁█▅▄▄▃▂▂▂</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▅▄▃▂▂▃▂▂▂▃▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.89438</td></tr><tr><td>eval/f1</td><td>0.79006</td></tr><tr><td>eval/loss</td><td>0.26952</td></tr><tr><td>eval/model_preparation_time</td><td>0.0029</td></tr><tr><td>eval/precision</td><td>0.88333</td></tr><tr><td>eval/recall</td><td>0.71461</td></tr><tr><td>eval/runtime</td><td>0.5643</td></tr><tr><td>eval/samples_per_second</td><td>567.042</td></tr><tr><td>eval/steps_per_second</td><td>35.44</td></tr><tr><td>train/epoch</td><td>0.26265</td></tr><tr><td>train/global_step</td><td>680</td></tr><tr><td>train/grad_norm</td><td>1.28732</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.3106</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">tmp_trainer</strong> at: <a href='https://wandb.ai/amirfvb/huggingface/runs/0bsillvz' target=\"_blank\">https://wandb.ai/amirfvb/huggingface/runs/0bsillvz</a><br> View project at: <a href='https://wandb.ai/amirfvb/huggingface' target=\"_blank\">https://wandb.ai/amirfvb/huggingface</a><br>Synced 7 W&B file(s), 0 media file(s), 36 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250622_203950-0bsillvz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f34b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad59b27a2524c42b6740b8b133a84fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "\n",
    "\n",
    "huggingface_hub.notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ddc7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b618b82f0f48c1a23c66eddfc6ae37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91323a04a1374122bd2e9dbce6cea664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\amirf\\.cache\\huggingface\\hub\\models--Hacker1337--distilbert-arxiv-checkpoint. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Hacker1337/distilbert-arxiv-checkpoint/commit/e9a5368700574158e6deeb2a93db39b6b97b1971', commit_message='Upload tokenizer', commit_description='', oid='e9a5368700574158e6deeb2a93db39b6b97b1971', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Hacker1337/distilbert-arxiv-checkpoint', endpoint='https://huggingface.co', repo_type='model', repo_id='Hacker1337/distilbert-arxiv-checkpoint'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model and tokenizer locally\n",
    "# local_dir = \"./distilbert-arxiv-checkpoint\"\n",
    "import os\n",
    "\n",
    "\n",
    "local_dir = os.path.expanduser(\"~/.cache/huggingface/checkpoints/distilbert-arxiv2\")\n",
    "model.save_pretrained(local_dir)\n",
    "tokenizer.save_pretrained(local_dir)\n",
    "\n",
    "# Push model and tokenizer to Hugging Face Hub\n",
    "model.push_to_hub(\"distilbert-arxiv-checkpoint\")\n",
    "tokenizer.push_to_hub(\"distilbert-arxiv-checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f772c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "local_dir = os.path.expanduser(\"~/.cache/huggingface/checkpoints/distilbert-arxiv2\")\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(local_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569935a3",
   "metadata": {},
   "source": [
    "### Testing on entities with only titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a930cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_titles_function(examples):\n",
    "    text = [create_prompt(title, \"\") for title, abstract in zip(examples[\"titles\"], examples[\"summaries\"])]\n",
    "    # text = [\"# title:\\n\" + title + \"\\n# abstract:\\n\" + abstract for title, abstract in zip(examples[\"titles\"], examples[\"summaries\"])]\n",
    "    return tokenizer(text, truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0222de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_titles_only_test_arxiv = dataset.train_test_split(test_size=0.2, seed=42)[\"test\"].map(preprocess_titles_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_eval_batch_size=16,\n",
    "    run_name=\"DistillBertFinetuning_2\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7018eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   1/1295 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\amirf\\YandexDisk\\SHAD\\ml\\semester2\\hw4_hf_finetue_service\\wandb\\run-20250622_204849-qi5xtx9d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amirfvb/huggingface/runs/qi5xtx9d' target=\"_blank\">tmp_trainer</a></strong> to <a href='https://wandb.ai/amirfvb/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/amirfvb/huggingface' target=\"_blank\">https://wandb.ai/amirfvb/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/amirfvb/huggingface/runs/qi5xtx9d' target=\"_blank\">https://wandb.ai/amirfvb/huggingface/runs/qi5xtx9d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2729688584804535, 'eval_model_preparation_time': 0.0032, 'eval_accuracy': 0.8944664413326895, 'eval_f1': 0.7889695658890777, 'eval_precision': 0.8737382378100941, 'eval_recall': 0.7191944796507534, 'eval_runtime': 19.5662, 'eval_samples_per_second': 529.23, 'eval_steps_per_second': 66.186}\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate(tokenized_titles_only_test_arxiv)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac18131",
   "metadata": {},
   "source": [
    "# Publishing model to huggingface hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d346a6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
