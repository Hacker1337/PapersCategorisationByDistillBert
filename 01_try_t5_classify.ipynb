{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "335b3dd5",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49915cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "model_path = \"distilbert/distilbert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17b8c5",
   "metadata": {},
   "source": [
    "# Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3596fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from article_classifier.dataset import load_arxiv_dataset\n",
    "\n",
    "dataset = load_arxiv_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d218d7",
   "metadata": {},
   "source": [
    "### Data preliminary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3ffa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "category_counts = Counter()\n",
    "\n",
    "for term in dataset[\"terms\"]:\n",
    "    for category in term:\n",
    "        category_counts[category] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2249dd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cs.CV', 30413),\n",
       " ('cs.LG', 29067),\n",
       " ('stat.ML', 15578),\n",
       " ('cs.AI', 7944),\n",
       " ('eess.IV', 2484),\n",
       " ('cs.RO', 1896),\n",
       " ('cs.CL', 1620),\n",
       " ('cs.NE', 1296),\n",
       " ('cs.CR', 717),\n",
       " ('cs.SI', 678),\n",
       " ('math.OC', 666),\n",
       " ('eess.SP', 621),\n",
       " ('cs.GR', 583),\n",
       " ('cs.MM', 523),\n",
       " ('cs.SY', 444),\n",
       " ('cs.IR', 442),\n",
       " ('cs.MA', 375),\n",
       " ('cs.HC', 359),\n",
       " ('eess.SY', 345),\n",
       " ('stat.AP', 294)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f84d38",
   "metadata": {},
   "source": [
    "1. make trainable categories.\n",
    "2. train test split.\n",
    "3. preprocess to tokens ids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edbc1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from article_classifier.dataset import labels, id2label, label2id, categorie2human\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7fc4a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_add_simple_categories(example):\n",
    "    labels = [0.] * len(id2label)\n",
    "    labels[label2id[\"CV\"]] = float(\"cs.CV\" in example[\"terms\"])\n",
    "    labels[label2id[\"AI\"]] = float(\"cs.AI\" in example[\"terms\"])\n",
    "    labels[label2id[\"ML\"]] = float((\"stat.ML\" in example[\"terms\"]) or (\"cs.LG\" in example[\"terms\"]))\n",
    "    labels[label2id[\"NE\"]] = float(\"cs.NE\" in example[\"terms\"])\n",
    "    labels[label2id[\"CL\"]] = float(\"cs.CL\" in example[\"terms\"])\n",
    "    example[\"labels\"] = labels\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(preprocess_add_simple_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cb245ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>terms</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
       "      <td>Stereo matching is one of the widely used tech...</td>\n",
       "      <td>[cs.CV, cs.LG]</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "      <td>[cs.CV, cs.AI, cs.LG]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
       "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
       "      <td>[cs.CV, cs.AI]</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
       "      <td>Consistency training has proven to be an advan...</td>\n",
       "      <td>[cs.CV]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background-Foreground Segmentation for Interio...</td>\n",
       "      <td>To ensure safety in automated driving, the cor...</td>\n",
       "      <td>[cs.CV, cs.LG]</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles  \\\n",
       "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
       "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
       "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
       "4  Background-Foreground Segmentation for Interio...   \n",
       "\n",
       "                                           summaries                  terms  \\\n",
       "0  Stereo matching is one of the widely used tech...         [cs.CV, cs.LG]   \n",
       "1  The recent advancements in artificial intellig...  [cs.CV, cs.AI, cs.LG]   \n",
       "2  In this paper, we proposed a novel mutual cons...         [cs.CV, cs.AI]   \n",
       "3  Consistency training has proven to be an advan...                [cs.CV]   \n",
       "4  To ensure safety in automated driving, the cor...         [cs.CV, cs.LG]   \n",
       "\n",
       "                      labels  \n",
       "0  [1.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "1  [1.0, 1.0, 1.0, 0.0, 0.0]  \n",
       "2  [1.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "4  [1.0, 0.0, 1.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d772693c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey on Semantic Stereo Matching / Semantic Depth Estimation\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Stereo matching is one of the widely used techniques for inferring depth from\\nstereo images owing to its robustness and speed. It has become one of the major\\ntopics of research since it finds its applications in autonomous driving,\\nrobotic navigation, 3D reconstruction, and many other fields. Finding pixel\\ncorrespondences in non-textured, occluded and reflective areas is the major\\nchallenge in stereo matching. Recent developments have shown that semantic cues\\nfrom image segmentation can be used to improve the results of stereo matching.\\nMany deep neural network architectures have been proposed to leverage the\\nadvantages of semantic segmentation in stereo matching. This paper aims to give\\na comparison among the state of art networks both in terms of accuracy and in\\nterms of speed which are of higher importance in real-time applications.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.iloc[0].titles)\n",
    "print()\n",
    "print(df.iloc[0].summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b432134c",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "745824c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    text = [\"# title:\\n\" + title + \"\\n# abstract:\\n\" + abstract for title, abstract in zip(examples[\"titles\"], examples[\"summaries\"])]\n",
    "    return tokenizer(text, truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6110596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_arxiv = dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "387f6ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['titles', 'summaries', 'terms', 'labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 51774\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "004efaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['titles', 'summaries', 'terms', 'labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 41419\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['titles', 'summaries', 'terms', 'labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 10355\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "split_dataset = tokenized_arxiv.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "print(split_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c138f441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(split_dataset[\"train\"][\"labels\"][:5][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c78f35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb71c4e",
   "metadata": {},
   "source": [
    "## Pipeline preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b39fafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "   predictions, labels = eval_pred\n",
    "   predictions = (predictions > 0).astype(int).reshape(-1)\n",
    "   return clf_metrics.compute(predictions=predictions, references=labels.astype(int).reshape(-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e963a5",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb8fd2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=len(id2label),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    problem_type=\"multi_label_classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74a830f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"~/.cache/huggingface/checkpoints/distilbert-arxiv\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"all\",\n",
    "    run_name=\"DistillBertFinetuning_1\",\n",
    "    logging_steps=20,\n",
    "    eval_on_start=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"test\"].select(range(20 * 16)),\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f1c4a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "wandb: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: No netrc file found, creating one.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\amirf\\_netrc\n",
      "wandb: Currently logged in as: amirfvb to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\amirf\\YandexDisk\\SHAD\\ml\\semester2\\hw4_hf_finetue_service\\wandb\\run-20250621_004206-d33wx68s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amirfvb/huggingface/runs/d33wx68s' target=\"_blank\">DistillBertFinetuning_1</a></strong> to <a href='https://wandb.ai/amirfvb/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/amirfvb/huggingface' target=\"_blank\">https://wandb.ai/amirfvb/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/amirfvb/huggingface/runs/d33wx68s' target=\"_blank\">https://wandb.ai/amirfvb/huggingface/runs/d33wx68s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1261' max='5178' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1261/5178 10:18 < 32:04, 2.03 it/s, Epoch 0.49/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.709293</td>\n",
       "      <td>0.278750</td>\n",
       "      <td>0.435421</td>\n",
       "      <td>0.278299</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.562300</td>\n",
       "      <td>0.460515</td>\n",
       "      <td>0.778125</td>\n",
       "      <td>0.672811</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.820225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.402100</td>\n",
       "      <td>0.386841</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.778589</td>\n",
       "      <td>0.719101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>0.317300</td>\n",
       "      <td>0.891250</td>\n",
       "      <td>0.781955</td>\n",
       "      <td>0.883853</td>\n",
       "      <td>0.701124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>0.291802</td>\n",
       "      <td>0.896250</td>\n",
       "      <td>0.790404</td>\n",
       "      <td>0.902017</td>\n",
       "      <td>0.703371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.273445</td>\n",
       "      <td>0.898125</td>\n",
       "      <td>0.794969</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.710112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.268600</td>\n",
       "      <td>0.289325</td>\n",
       "      <td>0.886250</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.887906</td>\n",
       "      <td>0.676404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.251900</td>\n",
       "      <td>0.276573</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.805031</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.719101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.288400</td>\n",
       "      <td>0.255820</td>\n",
       "      <td>0.905625</td>\n",
       "      <td>0.806658</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.707865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.251400</td>\n",
       "      <td>0.250590</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.719101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.269500</td>\n",
       "      <td>0.255362</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.804627</td>\n",
       "      <td>0.939940</td>\n",
       "      <td>0.703371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.265700</td>\n",
       "      <td>0.250130</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.808184</td>\n",
       "      <td>0.937685</td>\n",
       "      <td>0.710112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>0.249206</td>\n",
       "      <td>0.913750</td>\n",
       "      <td>0.829630</td>\n",
       "      <td>0.920548</td>\n",
       "      <td>0.755056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.257300</td>\n",
       "      <td>0.273746</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.786600</td>\n",
       "      <td>0.878116</td>\n",
       "      <td>0.712360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.255100</td>\n",
       "      <td>0.247252</td>\n",
       "      <td>0.910625</td>\n",
       "      <td>0.821026</td>\n",
       "      <td>0.926554</td>\n",
       "      <td>0.737079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.230500</td>\n",
       "      <td>0.249659</td>\n",
       "      <td>0.906875</td>\n",
       "      <td>0.808237</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.705618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>0.249626</td>\n",
       "      <td>0.905625</td>\n",
       "      <td>0.809584</td>\n",
       "      <td>0.922414</td>\n",
       "      <td>0.721348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.253900</td>\n",
       "      <td>0.238312</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.831266</td>\n",
       "      <td>0.927978</td>\n",
       "      <td>0.752809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>0.244589</td>\n",
       "      <td>0.908750</td>\n",
       "      <td>0.813776</td>\n",
       "      <td>0.941003</td>\n",
       "      <td>0.716854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.252300</td>\n",
       "      <td>0.256509</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.796547</td>\n",
       "      <td>0.882514</td>\n",
       "      <td>0.725843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.243500</td>\n",
       "      <td>0.235083</td>\n",
       "      <td>0.914375</td>\n",
       "      <td>0.829814</td>\n",
       "      <td>0.927778</td>\n",
       "      <td>0.750562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.272400</td>\n",
       "      <td>0.251897</td>\n",
       "      <td>0.900625</td>\n",
       "      <td>0.801001</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>0.719101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.245200</td>\n",
       "      <td>0.240224</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.805128</td>\n",
       "      <td>0.937313</td>\n",
       "      <td>0.705618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.271800</td>\n",
       "      <td>0.233497</td>\n",
       "      <td>0.908125</td>\n",
       "      <td>0.816020</td>\n",
       "      <td>0.920904</td>\n",
       "      <td>0.732584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.266900</td>\n",
       "      <td>0.232855</td>\n",
       "      <td>0.910625</td>\n",
       "      <td>0.818758</td>\n",
       "      <td>0.938953</td>\n",
       "      <td>0.725843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>0.234533</td>\n",
       "      <td>0.905625</td>\n",
       "      <td>0.806162</td>\n",
       "      <td>0.940120</td>\n",
       "      <td>0.705618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.235431</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.810606</td>\n",
       "      <td>0.925072</td>\n",
       "      <td>0.721348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.239700</td>\n",
       "      <td>0.240277</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.826303</td>\n",
       "      <td>0.922438</td>\n",
       "      <td>0.748315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.228300</td>\n",
       "      <td>0.242605</td>\n",
       "      <td>0.909375</td>\n",
       "      <td>0.817610</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.730337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.233500</td>\n",
       "      <td>0.233268</td>\n",
       "      <td>0.911250</td>\n",
       "      <td>0.822055</td>\n",
       "      <td>0.929178</td>\n",
       "      <td>0.737079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.244731</td>\n",
       "      <td>0.900625</td>\n",
       "      <td>0.797967</td>\n",
       "      <td>0.918129</td>\n",
       "      <td>0.705618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.234200</td>\n",
       "      <td>0.225260</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.843902</td>\n",
       "      <td>0.922667</td>\n",
       "      <td>0.777528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>0.246004</td>\n",
       "      <td>0.901250</td>\n",
       "      <td>0.803483</td>\n",
       "      <td>0.899721</td>\n",
       "      <td>0.725843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>0.223678</td>\n",
       "      <td>0.910625</td>\n",
       "      <td>0.822360</td>\n",
       "      <td>0.919444</td>\n",
       "      <td>0.743820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.252600</td>\n",
       "      <td>0.228568</td>\n",
       "      <td>0.914375</td>\n",
       "      <td>0.835928</td>\n",
       "      <td>0.894872</td>\n",
       "      <td>0.784270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.248300</td>\n",
       "      <td>0.225237</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.830097</td>\n",
       "      <td>0.902375</td>\n",
       "      <td>0.768539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>0.234331</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.813896</td>\n",
       "      <td>0.908587</td>\n",
       "      <td>0.737079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.237700</td>\n",
       "      <td>0.232401</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.812658</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.721348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.233700</td>\n",
       "      <td>0.223783</td>\n",
       "      <td>0.911875</td>\n",
       "      <td>0.822642</td>\n",
       "      <td>0.934286</td>\n",
       "      <td>0.734831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.217300</td>\n",
       "      <td>0.216396</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.829146</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.741573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>0.220335</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.823678</td>\n",
       "      <td>0.936963</td>\n",
       "      <td>0.734831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.223900</td>\n",
       "      <td>0.215873</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.833741</td>\n",
       "      <td>0.914209</td>\n",
       "      <td>0.766292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.221783</td>\n",
       "      <td>0.908750</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.921127</td>\n",
       "      <td>0.734831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.214835</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.839599</td>\n",
       "      <td>0.949008</td>\n",
       "      <td>0.752809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.207900</td>\n",
       "      <td>0.219905</td>\n",
       "      <td>0.914375</td>\n",
       "      <td>0.826362</td>\n",
       "      <td>0.947674</td>\n",
       "      <td>0.732584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.219242</td>\n",
       "      <td>0.915625</td>\n",
       "      <td>0.834761</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.766292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.195500</td>\n",
       "      <td>0.218888</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.828715</td>\n",
       "      <td>0.942693</td>\n",
       "      <td>0.739326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.234600</td>\n",
       "      <td>0.210166</td>\n",
       "      <td>0.920625</td>\n",
       "      <td>0.845311</td>\n",
       "      <td>0.922872</td>\n",
       "      <td>0.779775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.237600</td>\n",
       "      <td>0.215389</td>\n",
       "      <td>0.914375</td>\n",
       "      <td>0.829390</td>\n",
       "      <td>0.930168</td>\n",
       "      <td>0.748315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.249600</td>\n",
       "      <td>0.213178</td>\n",
       "      <td>0.914375</td>\n",
       "      <td>0.831073</td>\n",
       "      <td>0.920765</td>\n",
       "      <td>0.757303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.205900</td>\n",
       "      <td>0.235238</td>\n",
       "      <td>0.905625</td>\n",
       "      <td>0.814268</td>\n",
       "      <td>0.899457</td>\n",
       "      <td>0.743820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>0.222611</td>\n",
       "      <td>0.914375</td>\n",
       "      <td>0.833536</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.770787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>0.232240</td>\n",
       "      <td>0.911250</td>\n",
       "      <td>0.825980</td>\n",
       "      <td>0.908356</td>\n",
       "      <td>0.757303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.213813</td>\n",
       "      <td>0.919375</td>\n",
       "      <td>0.843636</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.782022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.251300</td>\n",
       "      <td>0.212523</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.842233</td>\n",
       "      <td>0.915567</td>\n",
       "      <td>0.779775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.229600</td>\n",
       "      <td>0.219870</td>\n",
       "      <td>0.910625</td>\n",
       "      <td>0.821026</td>\n",
       "      <td>0.926554</td>\n",
       "      <td>0.737079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.224600</td>\n",
       "      <td>0.216561</td>\n",
       "      <td>0.913125</td>\n",
       "      <td>0.828607</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.755056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>0.211967</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.764045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>0.212658</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.844282</td>\n",
       "      <td>0.920424</td>\n",
       "      <td>0.779775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.212473</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.845036</td>\n",
       "      <td>0.916010</td>\n",
       "      <td>0.784270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.205997</td>\n",
       "      <td>0.923750</td>\n",
       "      <td>0.855107</td>\n",
       "      <td>0.906801</td>\n",
       "      <td>0.808989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.221500</td>\n",
       "      <td>0.220929</td>\n",
       "      <td>0.911250</td>\n",
       "      <td>0.822500</td>\n",
       "      <td>0.926761</td>\n",
       "      <td>0.739326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.206200</td>\n",
       "      <td>0.215114</td>\n",
       "      <td>0.911875</td>\n",
       "      <td>0.826568</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.755056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\transformers\\trainer.py:2240\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2238\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\transformers\\trainer.py:2622\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2620\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[0;32m   2621\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 2622\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2631\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2632\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\transformers\\trainer.py:3095\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[0;32m   3093\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[1;32m-> 3095\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3096\u001b[0m     is_new_best_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_best_metric(metrics\u001b[38;5;241m=\u001b[39mmetrics, trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m   3098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_strategy \u001b[38;5;241m==\u001b[39m SaveStrategy\u001b[38;5;241m.\u001b[39mBEST:\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\transformers\\trainer.py:3044\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[1;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[0;32m   3043\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 3044\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3045\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   3047\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\transformers\\trainer.py:4173\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4170\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   4172\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 4173\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4174\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   4177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   4178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4181\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4183\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   4184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\transformers\\trainer.py:4388\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4385\u001b[0m         all_inputs\u001b[38;5;241m.\u001b[39madd(inputs_decode)\n\u001b[0;32m   4386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4387\u001b[0m     \u001b[38;5;66;03m# Pad labels here, preparing for preprocess_logits_for_metrics in next logits block.\u001b[39;00m\n\u001b[1;32m-> 4388\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4390\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mpad_across_processes(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\accelerate\\accelerator.py:2913\u001b[0m, in \u001b[0;36mAccelerator.pad_across_processes\u001b[1;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[0;32m   2880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpad_across_processes\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   2881\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2882\u001b[0m \u001b[38;5;124;03m    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\u001b[39;00m\n\u001b[0;32m   2883\u001b[0m \u001b[38;5;124;03m    they can safely be gathered.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2911\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m   2912\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\accelerate\\utils\\operations.py:407\u001b[0m, in \u001b[0;36mchained_operation.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 407\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DistributedOperationException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    409\u001b[0m         operation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\accelerate\\utils\\operations.py:677\u001b[0m, in \u001b[0;36mpad_across_processes\u001b[1;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[0;32m    674\u001b[0m     new_tensor[indices] \u001b[38;5;241m=\u001b[39m tensor\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_tensor\n\u001b[1;32m--> 677\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_pad_across_processes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\accelerate\\utils\\operations.py:126\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[1;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[0;32m    118\u001b[0m         {\n\u001b[0;32m    119\u001b[0m             k: recursively_apply(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m         }\n\u001b[0;32m    124\u001b[0m     )\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_on_other_type:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported types (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) passed to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. Only nested list/tuple/dicts of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects that are valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` should be passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    131\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\amirf\\miniconda3\\envs\\ml\\Lib\\site-packages\\accelerate\\utils\\operations.py:657\u001b[0m, in \u001b[0;36mpad_across_processes.<locals>._pad_across_processes\u001b[1;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[0;32m    654\u001b[0m     dim \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tensor\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;66;03m# Gather all sizes\u001b[39;00m\n\u001b[1;32m--> 657\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m    658\u001b[0m sizes \u001b[38;5;241m=\u001b[39m gather(size)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m    659\u001b[0m \u001b[38;5;66;03m# Then pad to the maximum size\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5343146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n",
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91187</td></tr><tr><td>eval/f1</td><td>0.82657</td></tr><tr><td>eval/loss</td><td>0.21511</td></tr><tr><td>eval/precision</td><td>0.91304</td></tr><tr><td>eval/recall</td><td>0.75506</td></tr><tr><td>eval/runtime</td><td>2.6911</td></tr><tr><td>eval/samples_per_second</td><td>118.912</td></tr><tr><td>eval/steps_per_second</td><td>7.432</td></tr><tr><td>train/epoch</td><td>0.48667</td></tr><tr><td>train/global_step</td><td>1260</td></tr><tr><td>train/grad_norm</td><td>3.18843</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.219</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">DistillBertFinetuning_1</strong> at: <a href='https://wandb.ai/amirfvb/huggingface/runs/d33wx68s' target=\"_blank\">https://wandb.ai/amirfvb/huggingface/runs/d33wx68s</a><br> View project at: <a href='https://wandb.ai/amirfvb/huggingface' target=\"_blank\">https://wandb.ai/amirfvb/huggingface</a><br>Synced 6 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250621_004206-d33wx68s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49ddc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and tokenizer locally\n",
    "# local_dir = \"./distilbert-arxiv-checkpoint\"\n",
    "import os\n",
    "\n",
    "\n",
    "local_dir = os.path.expanduser(\"~/.cache/huggingface/checkpoints/distilbert-arxiv\")\n",
    "model.save_pretrained(local_dir)\n",
    "# tokenizer.save_pretrained(local_dir)\n",
    "\n",
    "# # Push model and tokenizer to Hugging Face Hub\n",
    "# model.push_to_hub(\"distilbert-arxiv-checkpoint\")\n",
    "# # tokenizer.push_to_hub(\"distilbert-arxiv-checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f772c243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
